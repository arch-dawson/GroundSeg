\documentclass[10pt,letterpaper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\title{Matrix Methods Homework 8 \\ APPM 3310-003}
\author{Dawson Beatty}
\begin{document}
	\maketitle
	\section*{Section 5.1} 
	\subsection*{1}\textbf{Let $\mathbb{R}^2$ have the standard dot product. Classify the following pairs as: }
	\begin{align*}
	& i.) Basis & ii.) Orthogonal \: Basis & \qquad iii.) Orthonormal \: Basis \\
	\end{align*}
	\subsubsection*{(a)} 
	\begin{align*}
	& v_1 = \begin{bmatrix}
	-1 \\ 2
	\end{bmatrix}, v_2 = \begin{bmatrix}
	2 \\ 1 
	\end{bmatrix} \Rightarrow v_1 \cdot v_2 = 0, ||v_1|| \neq 1, \boxed{\text{orthogonal basis}}
	\end{align*}
	\subsubsection*{(b)}
	\begin{align*}
	& v_1 = \begin{bmatrix}
	\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}
	\end{bmatrix}, v_2 = \begin{bmatrix}
	- \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} 
	\end{bmatrix} \Rightarrow v_1 \cdot v_2 = 0, ||v_1|| = ||v_2|| = 1, \boxed{\text{orthonormal basis}}
	\end{align*}
	\subsubsection*{(c)}
		\begin{align*}
		& v_1 = \begin{bmatrix}
		-1 \\ -1
		\end{bmatrix}, v_2 = \begin{bmatrix}
		2 \\ 2 
		\end{bmatrix} \Rightarrow v_1 \cdot v_2 = -4, \boxed{\text{Not a basis}}
		\end{align*}
	\subsubsection*{(d)}
		\begin{align*}
		& v_1 = \begin{bmatrix}
		2 \\ 3
		\end{bmatrix}, v_2 = \begin{bmatrix}
		1 \\ -6 
		\end{bmatrix} \Rightarrow v_1 \cdot v_2 = -16, , \boxed{\text{basis}}
		\end{align*}
	\subsubsection*{(e)}
		\begin{align*}
		& v_1 = \begin{bmatrix}
		-1 \\ 0
		\end{bmatrix}, v_2 = \begin{bmatrix}
		0 \\ 3 
		\end{bmatrix} \Rightarrow v_1 \cdot v_2 = 0, ||v_2|| \neq 1, \boxed{\text{orthogonal basis}}
		\end{align*}
	\subsubsection*{(f)}
		\begin{align*}
		& v_1 = \begin{bmatrix}
		\frac{3}{5} \\ \frac{4}{5}
		\end{bmatrix}, v_2 = \begin{bmatrix}
		-\frac{4}{5} \\ \frac{3}{5} 
		\end{bmatrix} \Rightarrow v_1 \cdot v_2 = 0, ||v_1|| = ||v_2|| =  1, \boxed{\text{orthonormal basis}}
		\end{align*}
	\subsection*{3} \textbf{Repeat \textit{5.1.1} but use $\langle v,w \rangle = v_1w_1 + \frac{1}{9}v_2w_2$ as the inner product instead.}
	\subsubsection*{(d)}
	\begin{align*}
	& v_1 = \begin{bmatrix}
	2 \\ 3
	\end{bmatrix}, v_2 = \begin{bmatrix}
	1 \\ -6 
	\end{bmatrix} \Rightarrow v_1 \cdot v_2 = 2 + \frac{1}{9}(-18) = 0, \boxed{\text{orthogonal basis}}
	\end{align*}
	\subsubsection*{(e)}
	\begin{align*}
	& v_1 = \begin{bmatrix}
	-1 \\ 0
	\end{bmatrix}, v_2 = \begin{bmatrix}
	0 \\ 3 
	\end{bmatrix} \Rightarrow v_1 \cdot v_2 = 0, ||v_1|| = ||v_2|| = 1, \boxed{\text{orthonormal basis}}
	\end{align*}
	\subsection*{5} \textbf{Find all values of $a$ such that the vectors $\begin{bmatrix}
		a \\ 1
		\end{bmatrix}, \begin{bmatrix}
		-a \\ 1
		\end{bmatrix}$ form an orthogonal basis of $\mathbb{R}^2$ under... }
	\subsubsection*{(c)} \textbf{The inner product prescribed by the positive definite matrix $K = \begin{bmatrix}
		2 & -1 \\ -1 & 3
		\end{bmatrix}$}
		\begin{align*}
		& \begin{bmatrix}
		a \\ 1
		\end{bmatrix} \begin{bmatrix}
		2 & -1 \\ -1 & 3
		\end{bmatrix} = \begin{bmatrix}
		2a - 1 \\ -a + 3
		\end{bmatrix} \begin{bmatrix}
		-a \\ 1
		\end{bmatrix} = -2a^2 + a - a + 3 \\
		& \text{Vectors are orthogonal if their inner product equals zero, so set the above result equal to 0:} \\ 
		& 3 - 2a^2 = 0, \boxed{a = \sqrt{\frac{2}{3}}}
		\end{align*}
	\subsection*{9} \textbf{True or False: If $v_1, v_2, v_3$ are a basis for $\mathbb{R}^3$, then they form an orthogonal basis under some appropriately weighted inner product $\rangle v,w \rangle = av_1w_1 + bv_2w_2 + cv_3w_3$}
	
	Three vectors are linearly independent if and only if $0 \neq c_1v_1 + c_2 v_2 + c_3v_3 \: \forall \: c_i \text{ not all }0$. 
	
	$\boxed{\text{False}}$.  It's not possible to guarantee this property will hold, especially for vectors with all positive elements. Since $a,b,c$ are the diagonals of a positive definite matrix, they must be positive as well. 
	\subsection*{11}  
	\begin{proof}
		\textbf{Seek to prove that every orthogonal basis of $mathbb{R}^2$ under the standard dot product has the form $u_1 = \begin{bmatrix}
			\cos \theta \\ \sin \theta
			\end{bmatrix}, u_2 = \begin{bmatrix}
			\sin \theta \\ \pm \cos \theta
			\end{bmatrix}$}
		
		Every orthonormal basis using the standard dot product must satisfy the following properties: 
		$$
		\begin{bmatrix}
		x_1 \\ x_2
		\end{bmatrix} \cdot \begin{bmatrix}
		y_1 \\ y_2
		\end{bmatrix} = x_1y_1 + x_2y_2 = 0
		$$
		and 
		$$
		\norm{\begin{bmatrix}
			x_1 \\ x_2
			\end{bmatrix}} = \sqrt{x_1^2 + x_2^2} = 1, \: \norm{\begin{bmatrix}
			y_1 \\ y_2
			\end{bmatrix}} = \sqrt{y_1^2 + y_2^2} = 1
		$$
		
		The unit length condition is trivial, since 
		$$
		\sqrt{\sin^2\theta + \cos^2 \theta} = 1 \: \forall \: \theta
		$$
		
		For the other condition, we get 
		\begin{align*}
		\begin{bmatrix}
		\cos \theta \\ \sin \theta
		\end{bmatrix} \cdot \begin{bmatrix}
		\sin \theta \\ \pm \cos \theta
		\end{bmatrix} &= \cos \theta \sin \theta \pm \sin \theta \cos \theta = 0 \\
		& = \frac{1}{2} \big[ \sin (\theta + \theta) - \sin (\theta - \theta) \big] \pm \frac{1}{2} \big[ \sin (\theta + \theta) - \sin (\theta - \theta) \big] \\
		&= \frac{1}{2}\sin (2 \theta) \pm \frac{1}{2}\sin (2 \theta)
		\end{align*}
		At the point shown above, we split into two cases.  If a minus is chosen in the $\pm$, then the result of the whole expression will be zero, regardless of the choice of $\theta$. On the other hand, if plus is chosen, we get that $\sin (2 \theta) = 0$. Which is only true when $\theta = n \cdot \frac{\pi}{2}, n \: \epsilon \: \mathbb{Z}$.	
	\end{proof}
	\subsection*{22} 
	\subsubsection*{(a)} \textbf{Prove the vectors $v_1 = \begin{bmatrix}
		1 \\ 1 \\ 1
		\end{bmatrix}, v_2 = \begin{bmatrix}
		1 \\ 1 \\ -2
		\end{bmatrix}, v_3 = \begin{bmatrix}
			-1 \\ 1 \\ 0
			\end{bmatrix} $ form a basis of $\mathbb{R}^3$ with the standard dot product. }
		
		It's trivial to show the following. 
		$$
		\boxed{v_1 \cdot v_2 = 0, v_1 \cdot v_3 = 0, v_2 \cdot v_3 = 0}
		$$
	\subsubsection*{(b)} \textbf{Use orthogonality to write $v = \begin{bmatrix}
		1 \\ 2 \\ 3
		\end{bmatrix}$ as a combination of the three vectors from part $(a)$. }
	\begin{align*}
	& v = av_1 + bv_2 + cv_3 \\ 
	& a = \frac{\langle v, v_1 \rangle}{||v_1||} = \frac{6}{3} = 2 \\
	& b = \frac{\langle v, v_2 \rangle}{||v_2||} = \frac{-3}{6} = \frac{-1}{2} \\
	& c = \frac{\langle v, v_3 \rangle}{||v_3||} = \frac{1}{2}\\ 
	& \begin{bmatrix}
	1 \\ 2 \\ 3
	\end{bmatrix} = 2 \begin{bmatrix}
	1 \\ 1 \\ 1
	\end{bmatrix} - \frac{1}{2} \begin{bmatrix}
	1 \\ 1 \\ -2
	\end{bmatrix} + \frac{1}{2} \begin{bmatrix}
	-1 \\ 1 \\ 0
	\end{bmatrix} \\
	& = \begin{bmatrix}
	2 \\ 2 \\ 2
	\end{bmatrix} + \begin{bmatrix}
	-\frac{1}{2} \\ - \frac{1}{2} \\ 1 
	\end{bmatrix} + \begin{bmatrix}
	\frac{1}{2} \\ \frac{1}{2} \\ 0 
	\end{bmatrix} \boxed{= \begin{bmatrix}
	1 \\ 2 \\ 3
	\end{bmatrix}}
	\end{align*}
	\section*{Section 5.2}
	\subsection*{1}
	\subsubsection*{(a)} \textbf{Use Gram-Schmidt to find an orthonormal basis for $\mathbb{R}^3$ starting with the following vectors: $w_1 = \begin{bmatrix}
		1 \\ 0 \\ 1
		\end{bmatrix}, w_2 = \begin{bmatrix}
		1 \\ 1 \\ 1
		\end{bmatrix}, w_1 = \begin{bmatrix}
		-1 \\ 2 \\ 1
		\end{bmatrix}$}
	
	Arbitrarily choose $v_1 = w_1$ 
	\begin{align*}
	&v_2 = w_2 - \frac{\langle w_2, v_1 \rangle}{||v_1||^2} v_1 = \begin{bmatrix}
	1 \\ 1 \\ 1
	\end{bmatrix} - \frac{2}{2} \begin{bmatrix}
	1 \\ 0 \\ 1
	\end{bmatrix} = \begin{bmatrix}
	0 \\ 1 \\ 0
	\end{bmatrix} \\
	& v_3 = w_3 - \frac{\langle w_3, v_1 \rangle}{||v_1||^2}v_1 - \frac{\langle w_3, v_2 \rangle}{||v_2||^2}v_2= \begin{bmatrix}
	-1 \\ 2 \\ 1
	\end{bmatrix} - \frac{0}{2} \begin{bmatrix}
	1 \\ 0 \\ 1
	\end{bmatrix} - \frac{2}{1} \begin{bmatrix}
	0 \\ 1 \\ 0
	\end{bmatrix} = \begin{bmatrix}
	-1 \\ 0 \\ 1
	\end{bmatrix}
	\end{align*}
	Now to normalize... 
	$$
	\boxed{u_1 = \frac{v_1}{||v_1||} = \begin{bmatrix}
	\frac{1}{\sqrt{2}} \\ 0 \\ \frac{1}{\sqrt{2}}
	\end{bmatrix}, u_2 = \begin{bmatrix}
	0 \\ 1 \\ 0
	\end{bmatrix}, u_3 = \begin{bmatrix}
	-\frac{1}{\sqrt{2}} \\ 0 \\ \frac{1}{\sqrt{2}}
	\end{bmatrix}}
	$$
	\subsection*{3}
	\subsection*{4}\textbf{Use the Gram-Schmidt process to construct an orthonormal basis for the following subspaces of $\mathbb{R}^3$}
	\subsubsection*{(a)} \textbf{Plane spanned by $w_1 = \begin{bmatrix}
		0 \\ 2 \\ 1
		\end{bmatrix}, w_2 = \begin{bmatrix}
		1 \\ -2 \\ -1
		\end{bmatrix}$} 
		Can arbitrarily use $v_1 = w_1$. 
		\begin{align*}
		v_2 = w_2 - \frac{\langle w_2 , v_1 \rangle}{||v_1||^2} v_1 = \begin{bmatrix}
		1 \\ -2 \\ -1
		\end{bmatrix} - \frac{-5}{5} \begin{bmatrix}
		0 \\ 2 \\ 1
		\end{bmatrix} = \begin{bmatrix}
		1 \\ 0 \\ 0
		\end{bmatrix}
		\end{align*}
		Now we find the norms of each of those, since we need an orthonormal basis. 
		\begin{align*}
		\boxed{u_1 = \frac{v_1}{||v_1||} = \begin{bmatrix}
			0 \\ \frac{2}{\sqrt{3}} \\ \frac{1}{\sqrt{3}}
			\end{bmatrix}, \: u_2 = \frac{v_2}{||v_2||}  = \begin{bmatrix}
			1 \\ 0 \\ 0
			\end{bmatrix} } 
		\end{align*}
	\subsubsection*{(b)} \textbf{The plane $2x - y + 3z = 0$}
	We pick two arbitrary vectors in the plane, then use the Gram-Schmidt process to find an orthonormal basis. 
	 
	We'll pick $w_1 = \begin{bmatrix}
	-1 \\ 1 \\ 1
	\end{bmatrix}, w_2 = \begin{bmatrix}
	1 \\ 2 \\0 
	\end{bmatrix}$.  Again, arbitrarily pick $v_1 = w_1$
	$$
	v_2 = w_2 - \frac{\langle w_2, v_1 \rangle}{||v_1||^2} v_1 = \begin{bmatrix}
	1 \\ 2 \\ 0
	\end{bmatrix} - \frac{1}{3} \begin{bmatrix}
	-1 \\ 1 \\ 1
	\end{bmatrix} = \begin{bmatrix}
	\frac{4}{3} \\ \frac{5}{3} \\ \frac{-1}{3}
	\end{bmatrix}
	$$
	
	Now we just need to normalize each of our vectors.
	$$
	\boxed{u_1 = \frac{v_1}{||v_1||} = \begin{bmatrix}
		\frac{-1}{\sqrt{3}} \\ \frac{1}{\sqrt{3}} \\ \frac{1}{\sqrt{3}}
		\end{bmatrix}, u_2 = \frac{v_2}{||v_2||} = \begin{bmatrix}
		4 \sqrt{42} \\ 5 \sqrt{42} \\ -\sqrt{42}
		\end{bmatrix}}
	$$
	\subsubsection*{(c)} \textbf{Set of all vectors orthogonal to $\begin{bmatrix}
			1 \\ -1 \\ -2
		\end{bmatrix}$}
	Choose two vectors perpendicular to the vector above, we'll pick $w_1 = \begin{bmatrix}
	2 \\ 0 \\ 1
	\end{bmatrix}, w_2  =\begin{bmatrix}
	0 \\ 2 \\ -1
	\end{bmatrix}$ Set $v_1 = w_2$ because it's easy and we don't like change. 
	
	$$
	v_2 = w_2 - \frac{\langle w_2, v_1 \rangle}{||v_1||^2} v_1 = \begin{bmatrix}
	0  \\ 2 \\ -1 
	\end{bmatrix} - \frac{-1}{5} \begin{bmatrix}
	2 \\ 0 \\1
	\end{bmatrix} = \begin{bmatrix}
	\frac{2}{5} \\ 2 \\ \frac{-4}{5}
	\end{bmatrix}
	$$
	
	Now we normalize:
	$$
	\boxed{u_1 = \frac{v_1}{||v_1||} = \begin{bmatrix}
	\frac{2}{\sqrt{3}} \\ 0 \\ \frac{1}{\sqrt{3}}
	\end{bmatrix}, u_2 = \frac{v_2}{||v_2||} = \begin{bmatrix}
	4 \sqrt{30} \\ \frac{4 \sqrt{30}}{5} \\ -8 \sqrt{30}
	\end{bmatrix}}
	$$
	\subsection*{11} 
	\subsubsection*{(a)} \textbf{How many orthonormal bases does $\mathbb{R}$ have?} 
	Only $2$, since only $1$ and $-1$ have magnitude 1, and nothing can be `orthogonal' to a Real except 0.   
	\subsubsection*{(b)} \textbf{What about $\mathbb{R}^2$?}
	By \textit{Theorem 5.15}, any inner product space with dimension greater than one has infinitely many orthonormal bases. 
	\subsubsection*{(c)} \textbf{Does the answer change for a different inner product?}
	No.  \textit{Theorem 5.15} applies to \textit{any} inner product space, so our answer still holds. 
	\subsection*{15} \textbf{True or False: Reordering the original basis before starting Gram-Schmidt leads to the same orthogonal basis. }
	
	$\boxed{\text{FALSE}}$. Counter example:  Given the vectors $ w_1 = \begin{bmatrix}
	1 \\ 1
	\end{bmatrix}, w_2 = \begin{bmatrix}
	0 \\ 1
	\end{bmatrix}$ 
	
	First we choose $v_1 = w_1$
	$$
	v_2 = w_2 - \frac{\langle w_2, v_1 \rangle}{||v_1||^2} v_1 = \begin{bmatrix}
	0 \\ 1
	\end{bmatrix} - \frac{1}{2} \begin{bmatrix}
	1 \\ 1
	\end{bmatrix} = \begin{bmatrix}
	\frac{-1}{2} \\ \frac{1}{2}
	\end{bmatrix}
	$$
	Which gives us the basis of $\begin{bmatrix}
	1 \\ 1
	\end{bmatrix}, \begin{bmatrix}
	\frac{-1}{2} \\ \frac{1}{2}
	\end{bmatrix}$ 
	
	On the other hand, if we initially choose $v_1 = w_2$ (Really mixing things up here): 
	$$
	v_2 = w_1 - \frac{\langle w_1, v_1 \rangle}{||v_1||^2} v_1 = \begin{bmatrix}
	1 \\ 1
	\end{bmatrix} - \frac{1}{1} \begin{bmatrix}
	0 \\ 1
	\end{bmatrix} = \begin{bmatrix}
	1 \\ 0
	\end{bmatrix}
	$$ 
	Which gives us the basis $\begin{bmatrix}
	0 \\ 1
	\end{bmatrix}, \begin{bmatrix}
	1 \\ 0
	\end{bmatrix}$ 
	
	Both of the above are valid orthogonal bases, but they're not the same. 
	\section*{Section 5.3}
	\subsection*{1} \textbf{Determine which of the following matrices are orthogonal}
	\subsubsection*{(b)} \textbf{The matrix $b = \begin{bmatrix}
		\frac{12}{13} & \frac{5}{13} \\ 
		\frac{-5}{13} & \frac{12}{13} \\ 
		\end{bmatrix}$}
	Any orthogonal matrix $Q$ must satisfy the property $Q^TQ = I$
	
	$$
	b^Tb = \begin{bmatrix}
	\frac{12}{13} & \frac{-5}{13} \\ 
	\frac{5}{13} & \frac{12}{13} \\ 
	\end{bmatrix} \cdot \begin{bmatrix}
	\frac{12}{13} & \frac{5}{13} \\ 
	\frac{-5}{13} & \frac{12}{13} \\ 
	\end{bmatrix} = \begin{bmatrix}
	\frac{144}{13} + \frac{25}{13} & \frac{60}{13} - \frac{60}{13} \\
	\frac{60}{13} - \frac{60}{13} & \frac{25}{13} + \frac{144}{13} \\
	\end{bmatrix} = \begin{bmatrix}
	1 & 0 \\ 0 & 1
	\end{bmatrix} \checkmark
	$$ 
	\subsubsection*{(e)}
	$$e = \begin{bmatrix}
	\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\ 
	\frac{1}{3} & \frac{1}{4} & \frac{1}{5} \\ 
	\frac{1}{4} & \frac{1}{5} & \frac{1}{6} \\ 
	\end{bmatrix}
	$$
	
	$$
	e^T \cdot e = \begin{bmatrix}
	\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\ 
	\frac{1}{3} & \frac{1}{4} & \frac{1}{5} \\ 
	\frac{1}{4} & \frac{1}{5} & \frac{1}{6} \\ 
	\end{bmatrix} \cdot \begin{bmatrix}
	\frac{1}{2} & \frac{1}{3} & \frac{1}{4} \\ 
	\frac{1}{3} & \frac{1}{4} & \frac{1}{5} \\ 
	\frac{1}{4} & \frac{1}{5} & \frac{1}{6} \\ 
	\end{bmatrix} = \begin{bmatrix} \frac{61}{144} & \frac{3}{10} & \frac{7}{30}\\ \frac{3}{10} & \frac{769}{3600} & \frac{1}{6}\\ \frac{7}{30} & \frac{1}{6} & \frac{469}{3600} \end{bmatrix}
	$$ 
	\textit{Not} orthogonal. 
	\subsection*{8} 
	\subsubsection*{(a)}
	\begin{proof}
		\textbf{Seek to prove that the transpose of an orthogonal matrix is also orthogonal.}
		
		For any orthogonal matrix $Q$, we know that $Q^TQ=I$, by the definition of an orthogonal matrix. We also know that $Q^{-1} = Q^T$
		
		Let $F$ be an orthogonal matrix, which means that $F^TF= I$. We can take the transpose of $F$, $F^T$ and seek to show that $(F^T)^T F^T= I$. We know that $(F^T)^T$ is just $F$, and we can use the second property from above to show that $F^T = F^{-1}$.  Shown symbolically: 
		$$
		(F^T)^T F^T= F F^{-1} = I
		$$
		Showing that the transpose of an orthogonal matrix is itself orthogonal. $QED$
	\end{proof}
	\subsubsection*{(b)}
	\textbf{Explain why the rows od an $n \times n$ orthogonal matrix also form an orthonormal basis of $\mathbb{R}^n$} 
	To be a basis for $\mathbb{R}^n$, we need $n$ linearly independent elements of $\mathbb{R}^n$. 
	
	Let $A_{n \times n}$ be an orthogonal matrix composed of column vectors $\begin{bmatrix}
	v_1 & v_2 & \cdots & v_n
	\end{bmatrix}$  
	
	We know that $A$ is orthogonal, so $A^TA = I$, or 
	$$
	\begin{bmatrix}
	v^T_1  \\ v^T_2 \\ \vdots \\ v_n^T
	\end{bmatrix} \cdot \begin{bmatrix}
	v_1 & v_2 & \cdots & v_n
	\end{bmatrix} = \begin{bmatrix}
	v_1^T \cdot v_1  & v_1^T \cdot v_2 & \cdots & v_1^T \cdot v_n \\ 
	v_2^T \cdot v_1  & v_2^T \cdot v_2 & \cdots & v_2^T \cdot v_n \\
	\vdots & \vdots & \ddots & \vdots \\ 
	v_n^T \cdot v_1 & v_n^T \cdot v_2 & \cdots & v_n^T \cdot v_n
	\end{bmatrix} = I
	$$
	
	We get zero on each of the non-diagonal entries, showing that each of the $n$ vectors making up the rows of $A$ are orthogonal to all the others, which shows that we have $n$ orthogonal basis vectors.  
	
	We can also see that this basis is orthonormal, because on each of the diagonals, the magnitude of $v_1 v_1 = ||v_1||^2 = 1$. 
	\subsection*{10}  \textbf{True or False}
	\subsubsection*{(a)} \textbf{A matrix whose columns form an orthogonal basis of $\mathbb{R}^n$ is an orthogonal basis.} 
	
	$\boxed{\text{False}}$. Counter example: 
	$$
	\text{Let } A= \begin{bmatrix}
	1 & 1 \\ 1 & -1
	\end{bmatrix}, A^TA = \begin{bmatrix}
	2 & 0 \\ 0 & 2
	\end{bmatrix} \neq I
	$$ 
	The columns must be normalized for this to work. 
	\subsubsection*{(b)} \textbf{A matrix whose rows form an orthonormal basis of $mathbb{R}^n$ is an orthogonal basis. } 
	
	$\boxed{\text{True}}$. The only reason $(a)$ didn't work is that the columns weren't normalized, but the property holds in this case. 
	\subsubsection*{(c)} \textbf{An orthogonal matrix is symmetric if and only if it's a diagonal matrix. }
	$\boxed{\text{False}}$. Counter example: $\begin{bmatrix}
	0 & 1 \\ 1 & 0 
	\end{bmatrix}$ is an symmetric orthogonal matrix. 
	\subsection*{16}
	\subsection*{17}
	\subsubsection*{(a)}
	\subsubsection*{(c)}
	\subsection*{25}
	\subsubsection*{(b)}
	\subsection*{33}
	
\end{document}